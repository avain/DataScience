{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recognizing hand-written digits\n",
    "\n",
    "\n",
    "An example showing how the scikit-learn can be used to recognize images of\n",
    "hand-written digits.\n",
    "\n",
    "This example is commented in the\n",
    "`tutorial section of the user manual <introduction>`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5d62e46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
